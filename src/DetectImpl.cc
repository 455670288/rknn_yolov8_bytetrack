#include <iostream>
#include "DetectImpl.h"

using namespace multi_det;

static void dump_tensor_attr(rknn_tensor_attr *attr)
{
    std::string shape_str = attr->n_dims < 1 ? "" : std::to_string(attr->dims[0]);
    for (int i = 1; i < attr->n_dims; ++i)
    {
        shape_str += ", " + std::to_string(attr->dims[i]);
    }

    printf("  index=%d, name=%s, n_dims=%d, dims=[%s], n_elems=%d, size=%d, w_stride = %d, size_with_stride=%d, fmt=%s, "
           "type=%s, qnt_type=%s, "
           "zp=%d, scale=%f\n",
           attr->index, attr->name, attr->n_dims, shape_str.c_str(), attr->n_elems, attr->size, attr->w_stride,
           attr->size_with_stride, get_format_string(attr->fmt), get_type_string(attr->type),
           get_qnt_type_string(attr->qnt_type), attr->zp, attr->scale);
}

static unsigned char *load_data(FILE *fp, size_t ofst, size_t sz)
{
    unsigned char *data;
    int ret;

    data = NULL;

    if (NULL == fp)
    {
        return NULL;
    }

    ret = fseek(fp, ofst, SEEK_SET);
    if (ret != 0)
    {
        printf("blob seek failure.\n");
        return NULL;
    }

    data = (unsigned char *)malloc(sz);
    if (data == NULL)
    {
        printf("buffer malloc failure.\n");
        return NULL;
    }
    ret = fread(data, 1, sz, fp);
    return data;
}

static unsigned char *load_model(const char *filename, int *model_size)
{
    FILE *fp;
    unsigned char *data;

    fp = fopen(filename, "rb");
    if (NULL == fp)
    {
        printf("Open file %s failed.\n", filename);
        return NULL;
    }

    fseek(fp, 0, SEEK_END);
    int size = ftell(fp);

    data = load_data(fp, 0, size);

    fclose(fp);

    *model_size = size;
    return data;
}

static int saveFloat(const char *file_name, float *output, int element_size)
{
    FILE *fp;
    fp = fopen(file_name, "w");
    for (int i = 0; i < element_size; i++)
    {
        fprintf(fp, "%.6f\n", output[i]);
    }
    fclose(fp);
    return 0;
}


Detect::Impl::Impl()
{
    nms_threshold = NMS_THRESHOLD;      // 默认的NMS阈值
    conf_threshold = CONF_THRESHOLD; // 默认的置信度阈值
}

Detect::Impl::~Impl()
{
    deinitPostProcess();

    ret = rknn_destroy(ctx);

    if (model_data)
        free(model_data);

    if (input_attrs)
        free(input_attrs);
    if (output_attrs)
        free(output_attrs);
}

int Detect::Impl::init_model(const char *model_path, const float &nmsThreshold, const float &boxThreshold, const int &NPUcore, const std::vector<float> &confs)
{
    nms_threshold = nmsThreshold;
    conf_threshold = boxThreshold;

    if (confs.size() != OBJ_CLASS_NUM)
    {
        printf("Error: input confs.size() != OBJ_CLASS_NUM ! \n");
        return -1;
    }
    
    conf_thresholds = confs; 



    /* 加载模型 */
    printf("Loading model...\n");
    int model_data_size = 0;
    model_data = load_model(model_path, &model_data_size);

    //模型参数复用
    // if (share_weight == true){
    //     ret = rknn_dup_context(ctx_in, &ctx);
    // }
    // else{
    ret = rknn_init(&ctx, model_data, model_data_size, 0, NULL);
    // }
   
    if (ret < 0)
    {
        std::cout << "rknn_util_init failed" << std::endl;
        return -1;
    }

    // 设置模型绑定的核心/Set the core of the model that needs to be bound
    rknn_core_mask core_mask;
    switch (NPUcore)
    {
    case -1:
        core_mask = RKNN_NPU_CORE_AUTO;
        break;
    case 0:
        core_mask = RKNN_NPU_CORE_0;
        break;
    case 1:
        core_mask = RKNN_NPU_CORE_1;
        break;
    case 2:
        core_mask = RKNN_NPU_CORE_2;
        break;
    case 3:
        core_mask = RKNN_NPU_CORE_0_1_2;
        break;
    }
    ret = rknn_set_core_mask(ctx, core_mask);
    if (ret < 0)
    {
        printf("rknn_init core error ret=%d\n", ret);
        return -1;
    }
    rknn_sdk_version version;
    ret = rknn_query(ctx, RKNN_QUERY_SDK_VERSION, &version, sizeof(rknn_sdk_version));
    if (ret < 0)
    {
        printf("rknn_init error ret=%d\n", ret);
        return -1;
    }
    printf("sdk version: %s driver version: %s\n", version.api_version, version.drv_version);

    // 获取模型输入输出参数/Obtain the input and output parameters of the model
    ret = rknn_query(ctx, RKNN_QUERY_IN_OUT_NUM, &io_num, sizeof(io_num));
    if (ret < 0)
    {
        printf("rknn_init error ret=%d\n", ret);
        return -1;
    }
    printf("model input num: %d, output num: %d\n", io_num.n_input, io_num.n_output);

    // 设置输入参数/Set the input parameters
    input_attrs = (rknn_tensor_attr *)calloc(io_num.n_input, sizeof(rknn_tensor_attr));
    for (int i = 0; i < io_num.n_input; i++)
    {
        input_attrs[i].index = i;
        ret = rknn_query(ctx, RKNN_QUERY_INPUT_ATTR, &(input_attrs[i]), sizeof(rknn_tensor_attr));
        if (ret < 0)
        {
            printf("rknn_init error ret=%d\n", ret);
            return -1;
        }
        dump_tensor_attr(&(input_attrs[i]));
    }

    // 设置输出参数/Set the output parameters
    output_attrs = (rknn_tensor_attr *)calloc(io_num.n_output, sizeof(rknn_tensor_attr));
    for (int i = 0; i < io_num.n_output; i++)
    {
        output_attrs[i].index = i;
        ret = rknn_query(ctx, RKNN_QUERY_OUTPUT_ATTR, &(output_attrs[i]), sizeof(rknn_tensor_attr));
        dump_tensor_attr(&(output_attrs[i]));
    }

    if (input_attrs[0].fmt == RKNN_TENSOR_NCHW)
    {
        printf("model is NCHW input fmt\n");
        channel = input_attrs[0].dims[1];
        height = input_attrs[0].dims[2];
        width = input_attrs[0].dims[3];
    }
    else
    {
        printf("model is NHWC input fmt\n");
        height = input_attrs[0].dims[1];
        width = input_attrs[0].dims[2];
        channel = input_attrs[0].dims[3];
    }
    printf("model input height=%d, width=%d, channel=%d\n", height, width, channel);

    memset(inputs, 0, sizeof(inputs));
    inputs[0].index = 0;
    inputs[0].type = RKNN_TENSOR_UINT8;
    inputs[0].size = width * height * channel;
    inputs[0].fmt = RKNN_TENSOR_NHWC;
    inputs[0].pass_through = 0;
 
    return 0;
}  

rknn_context* Detect::Impl::get_pctx()
{
    return &ctx;
}


int Detect::Impl::detect(const cv::Mat &image, std::vector<int> *ids, std::vector<float> *conf, std::vector<cv::Rect> *boxes)
{
    // std::lock_guard<std::mutex> lock(mtx);

    // clear result
    ids->clear();
    conf->clear();
    boxes->clear();

    if (image.empty())
    {
        std::cout << "cannot open image..." << std::endl;
        return -1;
    }

    cv::Mat img;
    // cv::cvtColor(image, img, cv::COLOR_BGR2RGB);
    img = image.clone();
    img_width = img.cols;
    img_height = img.rows;

    // BOX_RECT pads;
    // memset(&pads, 0, sizeof(BOX_RECT));
    // cv::Size target_size(width, height);
    // cv::Mat resized_img(target_size.height, target_size.width, CV_8UC3);
    // 计算缩放比例/Calculate the scaling ratio
    // float scale_w = (float)target_size.width / img.cols;
    // float scale_h = (float)target_size.height / img.rows;


    letter_box.in_height = img.rows;
    letter_box.in_width = img.cols;
    letter_box.channel = img.channels();
    letter_box.target_width = width;
    letter_box.target_height = height;



    // 图像缩放/Image scaling
    cv::Mat resized_img;
    if (img_width != width || img_height != height)
    {   
        /***
        // rga
        rga_buffer_t src;
        rga_buffer_t dst;
        memset(&src, 0, sizeof(src));
        memset(&dst, 0, sizeof(dst));
        ret = resize_rga(src, dst, img, resized_img, target_size);
        if (ret != 0)
        {
            fprintf(stderr, "resize with rga error\n");
        }
        ****/
        
        /******
        // opencv
        float min_scale = std::min(scale_w, scale_h);
        scale_w = min_scale;
        scale_h = min_scale;
        letterbox(img, resized_img, pads, min_scale, target_size);
        ***/
        compute_letter_box(&letter_box);
        letter_box.reverse_available = true;
        if (img.rows != letter_box.resize_height || img.cols != letter_box.resize_width)
        {
            cv::resize(img, resized_img, cv::Size(letter_box.resize_width, letter_box.resize_height));
            cv::copyMakeBorder(resized_img, resized_img, letter_box.h_pad_top, letter_box.h_pad_bottom, letter_box.w_pad_left,
                               letter_box.w_pad_right, cv::BORDER_CONSTANT, cv::Scalar(114, 114, 114));
        }
        else
        {
            cv::copyMakeBorder(img, resized_img, letter_box.h_pad_top,       
                               letter_box.h_pad_bottom, letter_box.w_pad_left,
                               letter_box.w_pad_right, cv::BORDER_CONSTANT,
                               cv::Scalar(114, 114, 114));
        }

        inputs[0].buf = resized_img.data;
    }
    else
    {
        inputs[0].buf = img.data;
    }

    rknn_inputs_set(ctx, io_num.n_input, inputs);

    rknn_output outputs[io_num.n_output];
    memset(outputs, 0, sizeof(outputs));
    for (int i = 0; i < io_num.n_output; i++)
    {
        outputs[i].want_float = 0;
    }

    // 模型推理/Model inference
    ret = rknn_run(ctx, NULL);
    ret = rknn_outputs_get(ctx, io_num.n_output, outputs, NULL);
       
    // 后处理/Post-processing
    detect_result_group_t detect_result_group;

    // std::vector<float> out_scales;
    // std::vector<int32_t> out_zps;
    // for (int i = 0; i < io_num.n_output; ++i)
    // {
    //     out_scales.push_back(output_attrs[i].scale);
    //     out_zps.push_back(output_attrs[i].zp);
    // }

    post_process(ctx, outputs, &letter_box, conf_threshold, nms_threshold, &detect_result_group, width, height, io_num, output_attrs, true);

    //绘制框体/Draw the box
    // char text[256];
    // for (int i = 0; i < detect_result_group.count; i++)
    // {
    //     detect_result_t *det_result = &(detect_result_group.results[i]);
    //     sprintf(text, "%d %.1f%%", det_result->class_index, det_result->prop);

    //     int x1 = det_result->box.left;
    //     int y1 = det_result->box.top;
    //     int x2 = det_result->box.right;
    //     int y2 = det_result->box.bottom;
    //     rectangle(orig_img, cv::Point(x1, y1), cv::Point(x2, y2), cv::Scalar(255, 0, 0), 2);
    //     putText(orig_img, text, cv::Point(x1, y1 + 12), cv::FONT_HERSHEY_SIMPLEX, 0.4, cv::Scalar(255, 255, 255));
    // }
    
    ret = rknn_outputs_release(ctx, io_num.n_output, outputs);

    for (int i = 0; i < detect_result_group.count; i++)      //解码后的预测框存放在detect_result_group
    {
        detect_result_t *det_result = &(detect_result_group.results[i]);   

        // filter by conf_threshold
        if (det_result->prop < conf_thresholds[det_result->class_index])  //可对不同类别设置置信度阈值，再次进行过滤
        {
            continue;
        }

        ids->push_back(det_result->class_index);
        conf->push_back(det_result->prop);
        boxes->push_back(cv::Rect(det_result->box.left, det_result->box.top, det_result->box.right - det_result->box.left, det_result->box.bottom - det_result->box.top));
    }

    return ret;
}